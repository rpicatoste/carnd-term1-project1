{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Finding Lane Lines on the Road** \n",
    "### By *Ricardo Picatoste*\n",
    "***\n",
    "Here I describe the pipeline I created step by step.\n",
    "\n",
    "More comments on the code and how it has been done are explained in the writeup.md file.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "#from functions import *\n",
    "import os\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Read in an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get the image\n",
    "image_name = \"solidWhiteCurve.jpg\"\n",
    "image = mpimg.imread(image_name)\n",
    "\n",
    "# printing out some stats and plotting\n",
    "print('This image is:', type(image), 'with dimesions:', image.shape)\n",
    "plt.imshow( image ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build a Lane Finding Pipeline\n",
    "\n",
    "I will perform the pipeline on the example image step by step. For this I start by defining all the functions that are used in the pipeline.\n",
    "\n",
    "NOTE: The coefficients used along the pipeline have been hard coded for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Parameters for the different pipeline stages.\n",
    "# Parameters of the detection\n",
    "ker_size = 5\n",
    "low_threshold = 50\n",
    "high_threshold = 150\n",
    "\n",
    "# Parameters to select ROI as fraction of the image.\n",
    "fraction_top = 1/100*60     \n",
    "fraction_left_top = 1/100*40\n",
    "fraction_left_bottom = 1/100*10\n",
    "fraction_right_top = 1/100*60\n",
    "fraction_right_bottom = 1/100*90\n",
    "\n",
    "# Define the Hough transform parameters\n",
    "rho = 1*1.0            # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi/180 *1.0 # angular resolution in radians of the Hough grid\n",
    "threshold = 3          # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 20   # minimum number of pixels making up a line\n",
    "max_line_gap = 150     # maximum gap in pixels between connectable line segments\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the image is converted to gray and blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel \"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)    \n",
    "    \n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "im_gray = grayscale( image )\n",
    "im_blur = gaussian_blur( im_gray, ker_size )\n",
    "\n",
    "plt.imshow( im_blur ) \n",
    "print(\"image gray and blurred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the Canny transform to obtain the gradient of the image, and the result is cropped to have only the region of interest, that where the lane lines will mostly be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.  \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on\n",
    "    #the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "im_canny = canny( im_blur , low_threshold, high_threshold)\n",
    "\n",
    "# This time we are defining a four sided polygon to mask\n",
    "imshape = image.shape\n",
    "\n",
    "# The vertices of the region of interest are created from the image shape\n",
    "# information and the fractional parameters selected at the beginning. This \n",
    "# means that the ROI is chosen as a fraction of the original image, centered in\n",
    "# the bottom middle of the image. \n",
    "bottom = imshape[0]\n",
    "top = imshape[0]*fraction_top\n",
    "top_left = imshape[1]*fraction_left_top\n",
    "top_right = imshape[1]*fraction_right_top\n",
    "bottom_left = imshape[1]*fraction_left_bottom\n",
    "bottom_right = imshape[1]*fraction_right_bottom \n",
    "\n",
    "vertices = np.array([[  (bottom_left,   bottom),\\\n",
    "                        (top_left,      top), \\\n",
    "                        (top_right,     top), \\\n",
    "                        (bottom_right,  bottom)]], \\\n",
    "                        dtype=np.int32)\n",
    "\n",
    "im_cropped = region_of_interest( im_canny, vertices )\n",
    "\n",
    "plt.imshow( im_cropped ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the Hough transform is applied. Once applied, the draw_lines funtion is also used. This function will try to get, from the lines found, the one most likely representing the left lane and the same for the right lane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def line_get_distance(line):\n",
    "    \n",
    "    x1,y1,x2,y2 = line[0]\n",
    "    return math.sqrt( (x2-x1)**2 + (y2-y1)**2 )\n",
    "    \n",
    "def line_get_slope_and_offset(x1,y1,x2,y2):\n",
    "    \n",
    "    if x1 == x2:\n",
    "        m0 = math.inf\n",
    "    else:\n",
    "        m0 = (y2-y1)/(x2-x1)\n",
    "\n",
    "    b0 = y1 - m0*x1\n",
    "    \n",
    "    return m0, b0\n",
    "\n",
    "def line_get_x(m, b, y):\n",
    "    if m == 0.0:\n",
    "        return math.nan\n",
    "    if m == math.inf:\n",
    "        return 0.0 \n",
    "    \n",
    "    x = (y-b)/m        \n",
    "    return x\n",
    "\n",
    "def draw_lines(img, lines, roi_vertices, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    NOTE: choose the best lines represting the lanes and plot them. \n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    # Some values are obtained from the region of interest: the top and bottom\n",
    "    # limits, the center of the image.\n",
    "    middle_of_image = int( (roi_vertices[0][0][0]+roi_vertices[0][1][0]) / 2.0 )\n",
    "    ybottom = roi_vertices[0][0][1]        \n",
    "    ytop = roi_vertices[0][1][1]\n",
    "    \n",
    "    # Initialize values to obtain the best lines (longest ones).\n",
    "    left_max_distance = 0\n",
    "    right_max_distance = 0\n",
    "    left_max_index = -1\n",
    "    right_max_index = -1\n",
    "    \n",
    "    # Select the longest lines, one for the right and one for the left.\n",
    "    for i in range(len(lines)):\n",
    "        x1,y1,x2,y2 = lines[i][0]\n",
    "        \n",
    "        distance = line_get_distance(lines[i])\n",
    "        \n",
    "        m0, b0 = line_get_slope_and_offset(x1,y1,x2,y2)\n",
    "        # Get the x where the line starts at the bottom to help deciding left \n",
    "        # or right\n",
    "        xbottom = line_get_x(m0, b0, ybottom)\n",
    "        # Lines below a threshold degrees and above 180-threshold will be \n",
    "        # dropped (too horizontal). \n",
    "        threshold = 0.5\n",
    "        # Process right\n",
    "        if m0 >= threshold and line_get_x(m0, b0, ybottom) > middle_of_image: \n",
    "            if(distance > right_max_distance):\n",
    "                right_max_distance = distance\n",
    "                right_max_index = i\n",
    "        elif m0 <= -threshold and line_get_x(m0, b0, ybottom) < middle_of_image: \n",
    "            if(distance > left_max_distance):\n",
    "                left_max_distance = distance\n",
    "                left_max_index = i\n",
    "                \n",
    "    # Convert lines from the best found to complete lines.\n",
    "    for i in [left_max_index, right_max_index]:\n",
    "        if i == -1:\n",
    "            continue\n",
    "        \n",
    "        x1,y1,x2,y2 = lines[i][0]\n",
    "        # Get standard equation\n",
    "        m0, b0 = line_get_slope_and_offset(x1,y1,x2,y2)\n",
    "        \n",
    "        # Obtain the points corresponding to the bottom and top\n",
    "        if m0 == math.inf:\n",
    "            xbottom = x1\n",
    "            xtop = x1\n",
    "        elif m0 == 0.0:\n",
    "            xbottom = x1\n",
    "            xtop = x1\n",
    "        else:\n",
    "            xbottom = int((ybottom - b0) / m0)\n",
    "            xtop = int((ytop - b0) / m0)\n",
    "            \n",
    "        cv2.line(img, (xbottom, ybottom), (xtop, ytop), [0, 255, 0], thickness*3)\n",
    "\n",
    "def hough_lines(img, roi_vertices, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "    roi_vertices is the region of interest. It will be used to plot the lanes\n",
    "    will full extent from the best lines found for them. \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, \\\n",
    "                            np.array([]), \\\n",
    "                            minLineLength = min_line_len, \\\n",
    "                            maxLineGap = max_line_gap )\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines, roi_vertices)\n",
    "    return line_img\n",
    "    \n",
    "\n",
    "im_hough = hough_lines(im_cropped, vertices, rho, theta, threshold, min_line_length, max_line_gap)\n",
    "    \n",
    "plt.imshow( im_hough ) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the last step is to combine the lines obtained with the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "im_final = weighted_img(im_hough, image, α=0.8, β=1., λ=0.)\n",
    "plt.imshow( im_final ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the mentioned steps are combined in a single function, called my_pipeline, which will receive a single image and give back the result being this the combination of the original image and the lanes found superimposed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_pipeline(image, plot_all=0):\n",
    "    \n",
    "    # Parameters of the different pipeline stages\n",
    "    # Parameters of the detection\n",
    "    ker_size = 5\n",
    "    low_threshold = 50\n",
    "    high_threshold = 150\n",
    "\n",
    "    # Parameters to select ROI as fraction of the image.\n",
    "    fraction_top = 1/100*60     \n",
    "    fraction_left_top = 1/100*40\n",
    "    fraction_left_bottom = 1/100*10\n",
    "    fraction_right_top = 1/100*60\n",
    "    fraction_right_bottom = 1/100*90\n",
    "\n",
    "    # Define the Hough transform parameters\n",
    "    rho = 1*1.0            # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180 *1.0 # angular resolution in radians of the Hough grid\n",
    "    threshold = 3          # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 20   # minimum number of pixels making up a line\n",
    "    max_line_gap = 150     # maximum gap in pixels between connectable line segments\n",
    "\n",
    "    if(plot_all):\n",
    "        plt.imshow(image) \n",
    "        print(\"image\")\n",
    "        plt.show()\n",
    "    \n",
    "    im_gray = grayscale( image )\n",
    "    \n",
    "    if(plot_all):\n",
    "        plt.imshow( im_gray ) \n",
    "        print(\"image gray\")\n",
    "        plt.show()\n",
    "    \n",
    "    im_blur = gaussian_blur( im_gray, ker_size )\n",
    "    \n",
    "    if(plot_all):\n",
    "        plt.imshow( im_blur ) \n",
    "        print(\"image gray and blur\")\n",
    "        plt.show()\n",
    "    \n",
    "    im_canny = canny( im_blur , low_threshold, high_threshold)\n",
    "    \n",
    "    if(plot_all):\n",
    "        plt.imshow( im_canny ) \n",
    "        print(\"canny\")\n",
    "        plt.show()\n",
    "    \n",
    "    # This time we are defining a four sided polygon to mask\n",
    "    imshape = image.shape\n",
    "    \n",
    "    bottom = imshape[0]\n",
    "    top = imshape[0]*fraction_top\n",
    "    top_left = imshape[1]*fraction_left_top\n",
    "    top_right = imshape[1]*fraction_right_top\n",
    "    bottom_left = imshape[1]*fraction_left_bottom\n",
    "    bottom_right = imshape[1]*fraction_right_bottom \n",
    "                   \n",
    "    vertices = np.array([[  (bottom_left,   bottom),\\\n",
    "                            (top_left,      top), \\\n",
    "                            (top_right,     top), \\\n",
    "                            (bottom_right,  bottom)]], \\\n",
    "                            dtype=np.int32)\n",
    "    \n",
    "    im_cropped = region_of_interest( im_canny, vertices )\n",
    "    \n",
    "    if(plot_all):\n",
    "        plt.imshow( im_cropped ) \n",
    "        print(\"cropped\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Hough transform\n",
    "    # Run Hough on edge detected image\n",
    "    im_hough = hough_lines(im_cropped, vertices, rho, theta, threshold, min_line_length, max_line_gap)\n",
    "    \n",
    "    if(plot_all):\n",
    "        plt.imshow( im_hough ) \n",
    "        print(\"hough\")\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    im_final = weighted_img(im_hough, image, α=0.8, β=1., λ=0.)\n",
    "    if(plot_all):\n",
    "        plt.imshow( im_final ) \n",
    "        print(\"Final image\")\n",
    "        plt.show()\n",
    "\n",
    "    return im_final\n",
    "\n",
    "image = mpimg.imread(\"solidYellowCurve2.jpg\")\n",
    "im_result = my_pipeline(image)\n",
    "plt.imshow( im_result ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test on Videos\n",
    "\n",
    "Now the solution is run on the videos:\n",
    "\n",
    "- solidWhiteRight.mp4\n",
    "- solidYellowLeft.mp4\n",
    "- challenge.mp4\n",
    "\n",
    "And the results saved in the folder results\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "def process_image(image):\n",
    "    result = my_pipeline(image)\n",
    "    return result\n",
    "\n",
    "directory = os.path.dirname(\"results/\")\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "        \n",
    "# next video\n",
    "white_output = 'results\\white.mp4'\n",
    "clip1 = VideoFileClip('input_videos\\solidWhiteRight.mp4')\n",
    "white_clip = clip1.fl_image(process_image) \n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "print(\"First video done\")\n",
    "\n",
    "# next video\n",
    "yellow_output = 'results\\yellow.mp4'\n",
    "clip2 = VideoFileClip('input_videos\\solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)\n",
    "print(\"second video done\")\n",
    "\n",
    "# next video\n",
    "challenge_output = 'results\\chal.mp4'\n",
    "clip2 = VideoFileClip('input_videos\\challenge.mp4')\n",
    "challenge_clip = clip2.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)\n",
    "print(\"extra video done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Play the first video inline, or from the results folder in the project folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the second video in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the same with the challenge video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Writeup and Submission\n",
    "\n",
    "More comments on the writeup file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
